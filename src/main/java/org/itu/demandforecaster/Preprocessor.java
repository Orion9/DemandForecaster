package org.itu.demandforecaster;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.ml.feature.OneHotEncoder;
import org.apache.spark.ml.feature.StringIndexer;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.ml.tuning.TrainValidationSplit;
import org.apache.spark.ml.tuning.TrainValidationSplitModel;
import org.apache.spark.sql.DataFrame;
import org.apache.spark.sql.SQLContext;

/**
 * Created by Group 1.
 */

public class Preprocessor {
    /**
     * Attributes
     */

    // DataFrames generated by data files.
    protected DataFrame rawData;
    protected DataFrame trainingData;
    protected DataFrame testData;
    protected DataFrame processedData;

    // Objects for data preprocessing.
    public StringIndexer categoryIndexer, dayOfWeekIndexer;
    public OneHotEncoder dayOfWeekEncoder, categoryEncoder;
    public VectorAssembler vectorAssembler;

    // Debugging purposes only.
    public DataFrame debug;

    /**
     * When a new object is derived, it sets up necessary indexers and encoders
     * according to the necessary columns. Basically, it extracts necessary
     * features for prediction model.
     */
    public Preprocessor(){
        categoryIndexer = new StringIndexer()
                .setInputCol("category")
                .setOutputCol("categoryIndex");

        dayOfWeekIndexer = new StringIndexer()
                .setInputCol("dayOfWeek")
                .setOutputCol("dayOfWeekIndex");

        dayOfWeekEncoder = new OneHotEncoder()
                .setInputCol("dayOfWeekIndex")
                .setOutputCol("dayOfWeekVector");

        categoryEncoder = new OneHotEncoder()
                .setInputCol("categoryIndex")
                .setOutputCol("categoryVector");

        String[] cols = {"categoryVector", "dayOfWeekVector"};
        vectorAssembler = new VectorAssembler()
                .setInputCols(cols)
                .setOutputCol("features");
    }

    public void loadData() {
        SparkConf sparkConf = Configuration.getSparkConfig().config;
        JavaSparkContext sparkContext = new JavaSparkContext(sparkConf);
        SQLContext sqlContext = new SQLContext(sparkContext);

        rawData = sqlContext.read()
                .format("com.databricks.spark.csv")
                .option("header", "true")
                .option("inferSchema", "true")
                .load("transactions.csv")
                .repartition(6);
        rawData.registerTempTable("RawTrainData");
        processedData = sqlContext.sql("SELECT cast(amount as double) label, category, weekofyear(date) weekOfYear, " +
                "date_format(date, 'EEEE') dayOfWeek FROM RawTrainData").na().drop();


        // After loading training data some of it will be split as test data. Here 90% of data taken as training data.
        DataFrame[] splits = processedData.randomSplit(new double[]{0.9, 0.1});

        trainingData = splits[0];
        testData = splits[1];
    }

    public TrainValidationSplitModel fitModel( TrainValidationSplit tvs, DataFrame data){

        System.out.println("Fitting data");
        TrainValidationSplitModel model = tvs.fit(trainingData);
        System.out.println("Now performing test on hold out set");

        DataFrame holdout = model.transform(testData).select("prediction","label");

        holdout.printSchema();
        System.out.println("tita");
        //RegressionMetrics rm = new RegressionMetrics(holdout.rdd().map();
                //x => (x(0).asInstanceOf[Double], x(1).asInstanceOf[Double])))

         //       Accumulator<Integer> accum = sc.accumulator(0);
       // data.map(x -> { accum.add(x); return f(x); });
/*
        System.out.println("Test Metcis");
        System.out.println("Test Explained Variance:");
        System.out.println(rm.explainedVariance());
        System.out.println("Test R^2 Coef:");
        System.out.println(rm.r2());
        System.out.println("Test MSE");
        System.out.println(rm.meanSquaredError());
        System.out.println("Test RMSE");
        System.out.println(rm.rootMeanSquaredError());
*/
        return model;
    }

    /**
     * Getters and setters.
     */

    public DataFrame getRawData() {
        return rawData;
    }

    public void setRawData(DataFrame rawData) {
        this.rawData = rawData;
    }

    public DataFrame getTestData() {
        return testData;
    }

    public void setTestData(DataFrame testData) {
        this.testData = testData;
    }

    public DataFrame getProcessedData() {
        return processedData;
    }

    public void setProcessedData(DataFrame processedData) {
        this.processedData = processedData;
    }
}
