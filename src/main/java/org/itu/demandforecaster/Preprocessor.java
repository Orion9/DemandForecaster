package org.itu.demandforecaster;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.ml.feature.OneHotEncoder;
import org.apache.spark.ml.feature.StringIndexer;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.sql.DataFrame;
import org.apache.spark.sql.SQLContext;

/**
 * Created by Group 1.
 */

public class Preprocessor {
    /**
     * Attributes
     */

    // DataFrames generated by data files.
    protected DataFrame rawData;
    protected DataFrame trainingData;
    protected DataFrame testData;
    protected DataFrame processedData;

    // Objects for data preprocessing.
    public StringIndexer categoryIndexer, dayOfWeekIndexer, subcategoryIndexer, dateIndexer;
    public OneHotEncoder dayOfWeekEncoder, categoryEncoder, subcategoryEncoder, dateEncoder;
    public VectorAssembler vectorAssembler;

    protected JavaSparkContext sparkContext;
    protected SQLContext sqlContext;

    /**
     * When a new object is derived, it sets up necessary indexers and encoders
     * according to the necessary columns. Basically, it extracts necessary
     * features for prediction model.
     */
    public Preprocessor(){
        categoryIndexer = new StringIndexer()
                .setInputCol("category")
                .setOutputCol("categoryIndex")
                .setHandleInvalid("skip");

        subcategoryIndexer = new StringIndexer()
                .setInputCol("subcategory")
                .setOutputCol("subcategoryIndex")
                .setHandleInvalid("skip");

        dayOfWeekIndexer = new StringIndexer()
                .setInputCol("dayOfWeek")
                .setOutputCol("dayOfWeekIndex")
                .setHandleInvalid("skip");

        dateIndexer = new StringIndexer()
                .setInputCol("Date")
                .setOutputCol("dateIndex")
                .setHandleInvalid("skip");

        dayOfWeekEncoder = new OneHotEncoder()
                .setInputCol("dayOfWeekIndex")
                .setOutputCol("dayOfWeekVector");

        categoryEncoder = new OneHotEncoder()
                .setInputCol("categoryIndex")
                .setOutputCol("categoryVector");

        subcategoryEncoder = new OneHotEncoder()
                .setInputCol("subcategoryIndex")
                .setOutputCol("subcategoryVector");

        dateEncoder = new OneHotEncoder()
                .setInputCol("dateIndex")
                .setOutputCol("dateVector");

        String[] cols = {"subcategoryVector", "categoryVector", "dayOfWeekVector", "dateVector"};
        vectorAssembler = new VectorAssembler()
                .setInputCols(cols)
                .setOutputCol("features");
    }

    public void loadData() {
        SparkConf sparkConf = Configuration.getSparkConfig().config;
        sparkContext = new JavaSparkContext(sparkConf);
        sqlContext = new SQLContext(sparkContext);

        rawData = sqlContext.read()
                .format("com.databricks.spark.csv")
                .option("header", "true")
                .option("inferSchema", "true")
                .load("transactions.csv")
                .repartition(6);
        rawData.registerTempTable("RawTrainData");
        processedData = sqlContext.sql("SELECT cast(amount as double) label, subcategory, category, day(date) Date, " +
                "date_format(date, 'EEEE') dayOfWeek FROM RawTrainData").na().drop();


        // After loading training data some of it will be split as test data. Here 90% of data taken as training data.
        DataFrame[] splits = processedData.randomSplit(new double[]{0.7, 0.3});

        trainingData = splits[0];
        testData = splits[1];
    }



    /**
     * Getters and setters.
     */

    public DataFrame getRawData() {
        return rawData;
    }

    public void setRawData(DataFrame rawData) {
        this.rawData = rawData;
    }

    public DataFrame getTestData() {
        return testData;
    }

    public void setTestData(DataFrame testData) {
        this.testData = testData;
    }

    public DataFrame getProcessedData() {
        return processedData;
    }

    public void setProcessedData(DataFrame processedData) {
        this.processedData = processedData;
    }

    public DataFrame getTrainingData() { return trainingData; }

    public void setTrainingData(DataFrame trainingData) { this.trainingData = trainingData; }

    public JavaSparkContext getSparkContext() {
        return sparkContext;
    }

    public SQLContext getSqlContext() {
        return sqlContext;
    }
}
